AWSTemplateFormatVersion: '2010-09-09'
Description: AWS CloudFormation template to create Q Business resources

Resources:

  S3CopyLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/CloudWatchLogsFullAccess
      Path: /

  S3CopyLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda Function with code to copy sample data to S3 bucket
      Handler: index.lambda_handler
      Runtime: python3.9
      Timeout: 300
      Role: !GetAtt S3CopyLambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import json
          import io
          import zipfile          
          import logging
          import threading
          import boto3
          import cfnresponse
          import os
          from botocore.exceptions import ClientError
          # Initial setup
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          def copy_objects(source_bucket, dest_bucket, prefix, objects):
              s3 = boto3.client('s3')
              for o in objects:
                  key = prefix + o
                  if o == 'pca-sample-output-parsedFiles.zip':
                    zip_obj = s3.get_object(Bucket=source_bucket, Key=key)
                    buffer = io.BytesIO(zip_obj['Body'].read())
            
                    # Unzip the file
                    with zipfile.ZipFile(buffer) as zip_file:
                      for filename in zip_file.namelist():
                        file_content = zip_file.read(filename)
                    
                        # Upload each file from the zip to the destination bucket
                        s3.put_object(Bucket=dest_bucket, Key=filename, Body=file_content)
                        print(f'Unzipped and uploaded: {filename}')

                  else:
                    copy_source = {
                      'Bucket': source_bucket,
                      'Key': key
                    }
                    print('copy_source: %s' % copy_source)
                    print('dest_bucket = %s' % dest_bucket)
                    print('key = %s' % o)
                    s3.copy_object(CopySource=copy_source, Bucket=dest_bucket,
                      Key=o)
          def delete_objects(bucket, prefix, objects):
              s3 = boto3.client('s3')
              objects = {'Objects': [{'Key': prefix + o} for o in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)
          def timeout(event, context):
              logging.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)
          def lambda_handler(event, context):
              # make sure we send a failure to CloudFormation if the function
              # is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis()
                      / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()
              print('Received event: %s' % json.dumps(event))
              status = cfnresponse.SUCCESS
              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  prefix = event['ResourceProperties']['Prefix']
                  objects = event['ResourceProperties']['Objects']
                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, prefix, objects)
                  else:
                      copy_objects(source_bucket, dest_bucket, prefix, objects)
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED
              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)

  S3CopyCustomResource:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt S3CopyLambda.Arn
      SourceBucket: !Ref AssetBucketName
      DestBucket: !Ref S3Bucket
      Prefix: !Ref AssetBucketPrefix
      Objects:
        - pca-sample-output-parsedFiles.zip

  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true


  CloudFrontOriginAccessIdentity:
    Type: AWS::CloudFront::CloudFrontOriginAccessIdentity
    Properties:
      CloudFrontOriginAccessIdentityConfig:
        Comment: !Sub ${AWS::StackName} Origin Access Identity

  CloudFrontOriginAccessControl:
    Type: AWS::CloudFront::OriginAccessControl
    Properties:
      OriginAccessControlConfig:
        Name: !Sub ${S3Bucket}.s3.us-east-1.amazonaws.com
        Description: Origin Access Control for S3 Bucket
        OriginAccessControlOriginType: s3
        SigningBehavior: always
        SigningProtocol: sigv4

  CloudFrontDistribution:
    Type: AWS::CloudFront::Distribution
    Properties:
      DistributionConfig:
        Enabled: true
        Origins:
          - DomainName: !GetAtt S3Bucket.DomainName
            Id: !Ref S3Bucket
            S3OriginConfig: {}
            OriginAccessControlId: !Ref CloudFrontOriginAccessControl
        DefaultCacheBehavior:
          TargetOriginId: !Ref S3Bucket
          ViewerProtocolPolicy: allow-all
          AllowedMethods:
            - GET
            - HEAD
          CachedMethods:
            - GET
            - HEAD
          Compress: true
          ForwardedValues:
            QueryString: false
            Cookies:
              Forward: none
        ViewerCertificate:
          CloudFrontDefaultCertificate: true
        PriceClass: PriceClass_100
        HttpVersion: http2
        IPV6Enabled: true
        ContinuousDeploymentPolicyId: ''
        Staging: false

  S3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3Bucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: AllowCloudFrontServicePrincipal
            Effect: Allow
            Principal:
              Service: cloudfront.amazonaws.com
            Action: s3:GetObject
            Resource: !Sub arn:aws:s3:::${S3Bucket}/*
            Condition:
              StringEquals:
                AWS:SourceArn: !Sub arn:aws:cloudfront::${AWS::AccountId}:distribution/${CloudFrontDistribution}
    DependsOn:
      - CloudFrontDistribution

  ## Metadata file generation
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: LambdaS3Policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !Sub arn:aws:s3:::${S3Bucket}/*
                  - !Sub arn:aws:s3:::${S3Bucket}

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub ${AWS::StackName}-GenerateMetadata
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.9
      Timeout: 120
      Environment:
        Variables:
          CLOUDFRONT_DOMAIN: !GetAtt CloudFrontDistribution.DomainName
          BUCKET_NAME: !Ref S3Bucket
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import cfnresponse
          s3 = boto3.client('s3')
          def handler(event, context):
              try:
                  # Check if the environment variables are set
                  cloudfront_domain = os.getenv('CLOUDFRONT_DOMAIN')
                  bucket_name = os.getenv('BUCKET_NAME')
                  if not cloudfront_domain or not bucket_name:
                      raise ValueError("Environment variables CLOUDFRONT_DOMAIN and BUCKET_NAME must be set")
                  # List objects in the bucket
                  response = s3.list_objects_v2(Bucket=bucket_name)
                  for obj in response.get('Contents', []):
                      key = obj['Key']
                      if not key.startswith('meta/') and not key.endswith('.metadata.json'):
                          metadata = {
                              "DocumentId": key,
                              "Attributes": {
                                  "_source_uri": f"https://{cloudfront_domain}/{key}"
                              },
                              "Title": key.rsplit('/', 1)[-1]
                          }
                          metadata_key = f"meta/{key}.metadata.json"
                          s3.put_object(
                              Bucket=bucket_name,
                              Key=metadata_key,
                              Body=json.dumps(metadata),
                              ContentType='application/json'
                          )
                  # Send success response to CloudFormation
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
              except ValueError as ve:
                  print("Environment variable error: ", str(ve))
                  # Send failure response to CloudFormation with specific error message
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Reason': str(ve)})
              except Exception as e:
                  print("Error occurred: ", str(e))
                  # Send failure response to CloudFormation
                  cfnresponse.send(event, context, cfnresponse.FAILED, {})

  InvokeGenerateMetadata:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt LambdaFunction.Arn
    DependsOn:
      - CloudFrontDistribution
      - S3CopyCustomResource

### Parameters

Parameters:
  AssetBucketName:
    Type: String
    Default: Not-needed-for-self-paced-lab-in-customer-account
    Description: Name of the event asset bucket. For self paced labs in customer
      account, please leave the default value as is.
  AssetBucketPrefix:
    Type: String
    Default: Not-needed-for-self-paced-lab-in-customer-account
    Description: Prefix for the asset bucket. For self paced labs in customer
      account, please leave the default value as is.

Outputs:
  S3BucketUrl:
    Description: Your S3 bucket to be used as a data source
    Value: !Join
      - ''
      - - https://console.aws.amazon.com/s3/home?bucket=
        - !Ref S3Bucket
